{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"#### Kaggle 대회 랭킹 1위인 andrey lukyanenko의 notebook을 참고하여 정리한 내용입니다.\n\n## General information\n\nDon't Overfit II 에서는 binary classification을 합니다.\n\ntrain 샘플은 300열 250행의 크기이고, test 샘플은 train 샘플의 크기의 79배입니다.\t\n\n1)train data의 숫자가 test data의 수 보다 압도적으로 적은데다가, 아래에 EDA 결과가 나옵니다만, 2)target class data의 불균형으로 인해 과적합의 가능성이 매우 높습니다!\t\n\n본 competition의 목표는 오버피팅하지 않는 모델을 만드는 것입니다!!\n\n작성한 notebook에서는 아래와 같은 작업들을 수행합니다!\n\n* 인사이트를 얻기위해 항목에 대한 EDA를 합니다\n* permutation importance를 사용하여 가장 영향력 있는 항목을 찾습니다\t\n* 여러 모델을 비교합니다 - bayes classification, 선형 모델, 트리기반 모델 등을 해봅니다\n* 여러 종류의 feature selection 방법을 해봅니다 - ELI5 및 SHAP을 포함합니다 (+ feed forward, backward elimination, stepwise 방법도 고려할 것!)\n* hyper parameter 최적화를 해봅니다\n* feature engineering(몇 개의 feature를 추가해봄)\n\n![](https://cdn-images-1.medium.com/max/1600/1*vuZxFMi5fODz2OEcpG-S1g.png)"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# Libraries\nimport numpy as np\nimport pandas as pd\nfrom scipy import stats\npd.set_option('max_columns', None)\nimport json\nimport ast  # abstract syntax tree\nimport time\nimport datetime\nimport os\nfrom operator import itemgetter  # operator : 파이썬 고유 연산자에 대해 효율적인 함수 세트를 제공함, itemgetter : 복잡한 소스 및 객체에서 특정 값을 추출함.\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport plotly.offline as py  # offline으로 그래프를 만들어 local에 저장\npy.init_notebook_mode(connected=True)  # plotly 시작\nimport plotly.graph_objs as go  # 속성 값에 대한 유효성 제공\nimport plotly.tools as tls  # 플롯 모듈을 가져옴\n# 정우일님의 관련 블로그 https://wooiljeong.github.io/python/python_plotly/\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import model_selection\n# StratifiedKFold : KFold의 변형의 한 종류\n# RepeatedStratifiedKFold : 임의로 계층화 된(shuffling) K-Fold를 N번 반복\n# cross_val_score : 교차 검증 점수를 평가\n# accuracy_score : 교차 검증에서 정확도를 기록\n# f_classif : 분산 분석(ANOVA, 3개 이상 그룹에 대하여 평균의 동등성을 통계적으로 계산)의 F-value를 계산\n# mutual_info_classif : 이산 목표 변수에 대한 상호 정보를 추정\n# RFECV : 재귀적 feature elimination + top-N score에 해당하는 feature들에 대해 교차 검증을 실시\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, KFold, cross_val_score, GridSearchCV, RepeatedStratifiedKFold\nfrom sklearn.metrics import accuracy_score, roc_auc_score\nfrom sklearn.feature_selection import GenericUnivariateSelect, SelectPercentile, SelectKBest, f_classif, mutual_info_classif, RFECV\n\n\nimport xgboost as xgb\nimport lightgbm as lgb  # Gradient boosting의 변형 기법 중 하나. 다른 알고리즘과 달리, tree를 수직으로 확장하여 과적합 현상을 방지\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import NearestNeighbors\nfrom sklearn.ensemble import AdaBoostClassifier\n\nfrom sklearn import linear_model\nimport statsmodels.api as sm\n\n# ELI5 : 머신러닝 분류기를 디버그하고 예측을 설명하는데 도움을 줌\n# PermutationImportance : 블랙박스 예측기의 feature importance를 계산\n# SHAP : 모든 머신러닝 모델의 출력을 설명하는 게임 이론적 접근 방식 \nimport eli5  \nfrom eli5.sklearn import PermutationImportance\nimport shap\n\nfrom mlxtend.feature_selection import SequentialFeatureSelector as SFS\nfrom mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1c971fbc1a1b8249045b120924058402a036e665"},"cell_type":"code","source":"path = '/kaggle/input/dont-overfit-ii'\ntrain = pd.read_csv(f'{path}/train.csv')\ntest = pd.read_csv(f'{path}/test.csv')\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"구글 콜랩에서 사용하실 때는 컴퓨터에 첨부된 트레인 및 테스트 csv 파일을 컴퓨터에 다운로드 한 후 아래 코드를 실행하여 다시 그 파일들을 불러올 수 있게 됩니다.\n\n    from google.colab import files\n    uploaded = files.upload()\n\n그런 다음 아래 코드를 통해서 csv를 데이터프레임으로 바꿀 수 있게 됩니다.\n\n    import io\n    test = pd.read_csv(io.BytesIO(uploaded['test.csv']))\n    train = pd.read_csv(io.BytesIO(uploaded['train.csv']))"},{"metadata":{"_uuid":"7b40dd26ead2705ebf0058b0aa528c89a18aedbe"},"cell_type":"markdown","source":"<a id=\"de\"></a>\n## Data exploration"},{"metadata":{"trusted":true,"_uuid":"67a26174603f6a28709b7e0431aa431832ae608d"},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* id 열, target 열 및 300개의 feature가 있음을 알 수 있습니다\n* 익명으로 처리되었으므로 그 의미를 모릅니다\n* feature 간의 관계를 최대한 이해해보도록 하겠습니다."},{"metadata":{"trusted":true,"_uuid":"504b609f61494c21f8b078182e06191581ecb2a6"},"cell_type":"code","source":"train[train.columns[2:]].std().plot('hist');\nplt.title('Distribution of stds of all columns');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b7b0f65d2d5c999a44a3f71e013b1b6a6ff08980"},"cell_type":"code","source":"train[train.columns[2:]].mean().plot('hist');\nplt.title('Distribution of means of all columns');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* 모든 열의 평균 값이 -0.2와 0.15 사이임을 알 수 있습니다\t\n* 표준 편차는 매우 작습니다\n* 우리는 항목이 서로 매우 비슷하다고 말할 수 있습니다"},{"metadata":{"trusted":true,"_uuid":"d205e01b009224a3189903e1858dd592fb222d2d"},"cell_type":"code","source":"# we have no missing values\ntrain.isnull().any().any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"30e64cca712542d662201263914d8fc25496563e"},"cell_type":"code","source":"print('Distributions of first 28 columns')\nplt.figure(figsize=(26, 24))\nfor i, col in enumerate(list(train.columns)[2:30]):\n    plt.subplot(7, 4, i + 1)\n    plt.hist(train[col])\n    plt.title(col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"227daacd39977e5658c7e27db2686d8f65fdff3c"},"cell_type":"code","source":"train['target'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"89e9ed49ceff33d27cd1888336c3c46a38c5c8aa"},"cell_type":"markdown","source":"이 개요에서 우리는 다음을 볼 수 있습니다\n\n* 대상은 이진이며 약간의 불균형이 있습니다 -> 성능 측정 시, 단순히 accuracy만 고려하기에는 무리가 있음\n* 샘플의 26.8 %가 0 클래스에 속합니다\n* 열의 값은 다소 비슷합니다"},{"metadata":{"_uuid":"06df27b43428261da7daf02e708b934519d78ac2"},"cell_type":"markdown","source":"이제 상관 관계를 살펴 봅시다!"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = train[train.columns[2:]].corr()\n\n# Generate a mask for the upper triangle\nmask = np.triu(np.ones_like(corr, dtype=np.bool))\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(25, 25))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"열이 너무 많아서 위에서 도저히 읽을 수가 없습니다.\n\ntop correlated features를 보겠습니다."},{"metadata":{"trusted":true,"_uuid":"ae63462aa70238f0a2858de687dc7d2ae319589a"},"cell_type":"code","source":"corrs = train.corr().abs().unstack().sort_values(kind=\"quicksort\").reset_index()\ncorrs = corrs[corrs['level_0'] != corrs['level_1']]\ncorrs.tail(10)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d2d921a5d3bf606b88853988c10acad020685334"},"cell_type":"markdown","source":"feature 간의 상관 관계가 0.3보다 낮고 target과 가장 관련이 높은 feature의 상관 관계는 0.33입니다\t\n\n따라서 제거 할 수 있는 상관 관계가 높은 feature가 없으며, target과 상관 관계가 거의 없는 일부 feature를 삭제할 수 있습니다."},{"metadata":{},"cell_type":"markdown","source":"## Prepare the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train.drop(['id', 'target'], axis=1)\ny_train = train['target']\nX_test = test.drop(['id'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a4f28e1e3c847e2fe165034dd870154afb7fe939"},"cell_type":"markdown","source":"## Basic modelling\n\n기본 모델링을합니다\n\ntrain data가 충분하지 않기 때문에, 과적합의 가능성이 높아집니다.\n\n이를 방지하기 위해, model은 기본적으로 K-Fold Cross Validation 방식을 채택하겠습니다.\n\n이 떄, 성능 측정을 위해 sklearn의 cross_val_score 대신, roc_auc_score를 사용하도록 하겠습니다.\n\n왜냐하면 cross_val_score는,\t\n\n* 예측값을 제공하지 않는다.\n* 폴드로부터의 예측은 제공하지 않는다\n* 특정 변환을 적용할 수 없다. (EX : 특정 feature selector의 input formatting을 위한 변환 작업)\n* lgbm, catboost, xgboost와 같은 그래디언트 부스팅 모델은 cross_val_score로 전달할 수 없는 추가 매개 변수를 필요로한다.\t\n\n로직은 아래와 같습니다.\n\n```\nfor fold in folds:\n    get train and validation data\n    apply some transformations (if necessary)\n    train model\n    predict on validation data\n    calculate train and validation metrics(rou 커브의 auc score)\n    predict on test data\n```\n\n간단한 logistic regression을 사용하여 단계별로 코드를 작성할 것입니다."},{"metadata":{},"cell_type":"markdown","source":"[](http://i.imgur.com/QBuDOjs.jpg)"},{"metadata":{},"cell_type":"markdown","source":"먼저 몇 가지 사항을 정의 해 보겠습니다\t\n\n* Prediction은 우리의 예측이 될 것입니다\n* scores_train, scores_valid은 점수 리스트입니다\n* fold란 데이터를 나누는 방법입니다"},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = np.zeros(len(X_test))  # 예측 값(각 클래스의 출현 확률)을 저장할 배열\nscores_train = []  # train roc_auc_score\nscores_valid = []  # validation roc_auc_score\nfolds = StratifiedKFold(n_splits=20, shuffle=True, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"이제 폴드를 한 번 사용하여 트레인 데이터를 훈련 및 검증으로 분할합니다"},{"metadata":{"trusted":true},"cell_type":"code","source":"for fold_n, (train_index, valid_index) in enumerate(folds.split(X_train, y_train)):\n    X_train_fold, X_valid_fold = X_train.loc[train_index], X_train.loc[valid_index]\n    y_train_fold, y_valid_fold = y_train[train_index], y_train[valid_index]\n    break","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"이제 모델을 훈련시키고 roc 커브의 auc score를 계산할 수 있습니다."},{"metadata":{"trusted":true},"cell_type":"code","source":"# C값이 작을수록, 정규화의 강도가 커짐. 또한 feature가 매우 많은 경우, 영향력이 없는(계수가 0에 가까운) 변수를 제거하는 lasso 방식을 사용하는 것이 좋음.\nmodel = linear_model.LogisticRegression(class_weight='balanced', penalty='l1', C=0.1, solver='liblinear')\nmodel.fit(X_train_fold, y_train_fold)\ny_pred_train = model.predict(X_train_fold).reshape(-1,)  # train set 예측\ntrain_score = roc_auc_score(y_train_fold, y_pred_train)  # sensitivity(recall), 1-specificity 두 개의 축을 활용해, ROC 커브의 AUC 값 계산\n\ny_pred_valid = model.predict(X_valid_fold).reshape(-1,)  # validation set 예측\nvalid_score = roc_auc_score(y_valid_fold, y_pred_valid)  \n\n# roc_auc_score : https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc?hl=ko\n# sensitivity(민감도 or 재현율), specificity(특이도) : https://blog.naver.com/PostView.nhn?blogId=jesus24968&logNo=220734872380","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Train auc: {train_score:.4}. Valid auc: {valid_score:.4}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"위에서 설명한 로직을 토대로 함수를 만듭니다."},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(X_train, y_train, X_test, folds=folds, model=None):\n    prediction = np.zeros(shape = (len(X_test), 2))\n    scores_train = []\n    scores_valid = []\n    \n    # 지정된 fold 수 만큼 model training / train&valid set prediction / test set prediction을 수행 \n    for fold_n, (train_index, valid_index) in enumerate(folds.split(X_train, y_train)):\n        X_train_fold, X_valid_fold = X_train[train_index], X_train[valid_index]\n        y_train_fold, y_valid_fold = y_train[train_index], y_train[valid_index]\n        \n        model.fit(X_train_fold, y_train_fold)\n        \n        y_pred_train = model.predict(X_train_fold).reshape(-1,)\n        train_score = roc_auc_score(y_train_fold, y_pred_train)\n        scores_train.append(train_score)\n        \n        y_pred_valid = model.predict(X_valid_fold).reshape(-1,)\n        valid_score = roc_auc_score(y_valid_fold, y_pred_valid)\n        scores_valid.append(valid_score)\n\n        y_pred = model.predict_proba(X_test)  # 각 class(0 또는 1)의 출현 확률을 계산\n        prediction += y_pred\n\n    prediction /= folds.get_n_splits()\n    prediction = np.argmax(prediction, axis = 1) # 확률 값이 높은 인덱스를 선택(class)\n    \n    print(f'Mean train auc: {np.mean(scores_train):.4f}, std: {np.std(scores_train):.4f}.')\n    print(f'Mean valid auc: {np.mean(scores_valid):.4f}, std: {np.std(scores_valid):.4f}.')\n    \n    return scores_valid, prediction\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"기본 모델을 바탕으로 Logistic Regression 기법을 적용한 결과, 성능은 아래와 같습니다."},{"metadata":{"trusted":true},"cell_type":"code","source":"model = linear_model.LogisticRegression(class_weight='balanced', penalty='l1', C=0.1, solver='liblinear')\nscores, prediction = train_model(X_train.values, y_train, X_test, folds=folds,  model=model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Different ways of splitting data into folds\n\n데이터를 폴드로 나누는 방법에는 여러 가지가 있습니다\n* 가장 간단한 방법은 무작위로 나누는 것입니다: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html\n* 일반적으로 분류에는 더 나은 방법이 있긴 합니다 - https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html \n\nStratifiedKFold는 계층화 된 폴드를 반환하는 k-폴드의 변형입니다. (주로 StratifiedKFold는 분류 문제에서, KFold는 회귀 문제에서 사용)\n\n각 세트에는 각 세트의 샘플이 전체 세트와 거의 같은 비율로 포함되어 있습니다 (class biased한 problem을 최대한 해결하려 노력)\n\n* StratifiedKFold와 비슷한 RepeatedStratifiedKFold도 있는데 https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RepeatedStratifiedKFold.html 이는 그 안에서 여러번 반복됩니다\n\n우리는 RepeatedStratifiedKFold로 확인하겠습니다"},{"metadata":{"trusted":true},"cell_type":"code","source":"repeated_folds = RepeatedStratifiedKFold(n_splits=20, n_repeats=5, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = linear_model.LogisticRegression(class_weight='balanced', penalty='l1', C=0.1, solver='liblinear')\nscores, prediction = train_model(X_train.values, y_train, X_test, folds=repeated_folds, model=model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. mean auc가 증가한 것을 볼 수 있습니다 (KFold : 0.6871 -> RepeatedStratifiedKFold : 0.7124)"},{"metadata":{},"cell_type":"markdown","source":"## Approaches to feature selection\n\nfeature selection이 무엇이고 왜 중요한지 설명하겠습니다"},{"metadata":{"_uuid":"600682b545014ae67e19a8b04724e75767be6014"},"cell_type":"markdown","source":"\n### ELI5\n\nELI5는 ML 모델에 대한 설명을 제공하는 패키지입니다. 통합 패키지를 통해, 다양한 ML Model을 시각화할 수 있으며, 디버깅도 가능합니다.\n\n선형 모델뿐만 아니라 트리 기반 알고리즘에 대해서도 이를 수행 할 수 있습니다.\n\n여러 ML 프레임워크를 지원하며, 블랙 박스 모델(input에 따른 output을 제공하나, 내부 프로세스는 파악할 수 없는 모델)을 설명하는 방법을 제공합니다. \n\nex) Tree 기반 모델 : 트리의 깊이가 깊어질수록, feature의 수가 많아질수록, 어떠한 프로세스에 따라 tree의 분기를 실시하였는지 설명하기 힘들어진다.\n                    importance가 높은 feature에 대해 값을 바꾸면서 전체 모델 성능 변화를 확인하거나, imformation gain, 지니 계수 값의 변화를 확인하는 방식으로 설명하는 방법이 있으나,\n                    이 또한 한계점이 있다.\n\n모델의 매개 변수를 파악하고, 모델이 전체적으로 어떻게 동작하는지 확인."},{"metadata":{"trusted":true},"cell_type":"code","source":"eli5.show_weights(model, top=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f16f5fee606cb48d35c0cb95e123c7542aacac28"},"cell_type":"code","source":"(model.coef_ != 0).sum()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1c738de31f86152ced6cb35ddb8d3569e7b49a6e"},"cell_type":"markdown","source":"가중치가 매우 높은 항목과 가중치가 마이너스인 더 많은 항목이 있음을 알 수 있습니다\t\n\n실제로 ELI5에 따르면 중요한 항목은 32개만 있습니다\t\n\n이 항목들만 사용하여 모델을 구축해 봅시다"},{"metadata":{"trusted":true},"cell_type":"code","source":"eli5.formatters.as_dataframe.explain_weights_df(model).feature","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_features = [i[1:] for i in eli5.formatters.as_dataframe.explain_weights_df(model).feature if 'BIAS' not in i]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_features","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. Important information about ELI5:\n\n실제로 매우 간단하게 작동됩니다\t\nlogistic regression와 같은 모델의 model coefficient를 보여주거나 랜덤 포레스트와 같은 모델의 feature importance를 보여 줍니다\t\n\nELI5의 결과를 model coefficient와 비교해 봅니다"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, coef in enumerate(model.coef_[0]):\n    if coef != 0:\n        print(f'Feature {X_train.columns[i]} has coefficient {coef:.4f}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"여기에 중요한 결론이 있습니다\n\n모델에 계수(Coefficient) 또는 항목 중요도(feature importance)가 없는 경우 ELI5가 작동하지 않습니다\t\n\nSVC가 그런 예입니다\t"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_selected = train[top_features]\ny_train = train['target']\nX_test_selected = test[top_features]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = linear_model.LogisticRegression(class_weight='balanced', penalty='l1', C=0.1, solver='liblinear')\nscores, prediction = train_model(X_train_selected.values, y_train, X_test_selected, folds=repeated_folds, model=model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"모델이 훨씬 좋아졌다는 것을 알 수 있습니다 (Mean valid auc : before feature selection 0.7124 -> after 0.7526)"},{"metadata":{"_uuid":"fbee2b85bae60cf0607b977692306eb380582e5c"},"cell_type":"markdown","source":"<a id=\"eli5p\"></a>\n### Permutation importance\n\nELI5를 잘 이용하는 다른 방법이 하나 더 있습니다\n\nPermutation Feature Importance는 데이터가 테이블 형식일 때 훈련된 estimator에 사용할 수 있는 모델 검사 기술입니다\t \n\nPermutation Importance는 다음과 같은 방식으로 작동합니다\t\n\n* 모델을 train한다.\n* 하나의 유효성 검사 데이터 열을 지정하여, 행 데이터를 임의로 shuffling하고 점수를 계산한다.\n* 점수가 크게 떨어지면 항목이 중요하다는 의미이다.\n\nPermutation importance 참고 링크 : https://www.kaggle.com/dansbecker/permutation-importance"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train.drop(['id', 'target'], axis=1)\ny_train = train['target']\nX_test = test.drop(['id'], axis=1)\nmodel = linear_model.LogisticRegression(class_weight='balanced', penalty='l1', C=0.1, solver='liblinear')\nscores, prediction = train_model(X_train.values, y_train, X_test, folds=repeated_folds,  model=model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv(f'{path}/sample_submission.csv')\nsubmission['target'] = prediction\nsubmission.to_csv('submission_3.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"242439bf4036359fc07864ac41d0bccac6f1d9c6"},"cell_type":"code","source":"# permutation importance\nperm = PermutationImportance(model, random_state=1).fit(X_train, y_train)\neli5.show_weights(perm, top=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eli5.formatters.as_dataframe.explain_weights_df(perm).head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eli5.formatters.as_dataframe.explain_weights_df(perm).loc[eli5.formatters.as_dataframe.explain_weights_df(perm)['weight'] != 0].shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"실제로 모델에 영향을 끼치는 feature의 수는 32개 정도라는 것을 파악할 수 있습니다."},{"metadata":{"trusted":true},"cell_type":"code","source":"selected_weights = eli5.formatters.as_dataframe.explain_weights_df(perm).loc[eli5.formatters.as_dataframe.explain_weights_df(perm)['weight'] != 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"26dd053929c39014a3244d8d2471e8b2cdb5ac0f"},"cell_type":"code","source":"top_features = [i[1:] for i in selected_weights.feature if 'BIAS' not in i]\nX_train_selected = train[top_features]\ny_train = train['target']\nX_test_selected = test[top_features]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fcbc3e88b57bab0d1220c41d222540d42a445622"},"cell_type":"code","source":"model = linear_model.LogisticRegression(class_weight='balanced', penalty='l1', C=0.1, solver='liblinear')\nscores, prediction = train_model(X_train_selected.values, y_train, X_test_selected, folds=repeated_folds, model=model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"모델이 훨씬 좋아졌다는 것을 알 수 있습니다 (Mean valid auc : before feature selection 0.7124 -> after 0.7526)"},{"metadata":{"_uuid":"a010cfbba09f2846f05211678657f87614c219c4"},"cell_type":"markdown","source":"\n### SHAP\n\n또 다른 흥미로운 도구는 SHAP입니다\t\n\n다양한 모델에 대한 설명을 제공합니다"},{"metadata":{"trusted":true,"_uuid":"5869cb071f42e20e9e420c0a9d1ef584dd2b2417","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"model = linear_model.LogisticRegression(class_weight='balanced', penalty='l1', C=0.1, solver='liblinear')\nscores, prediction = train_model(X_train.values, y_train, X_test, folds=repeated_folds, model=model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"33c4481d2b911208738c7ffc7042259108bb5736","scrolled":false},"cell_type":"code","source":"explainer = shap.LinearExplainer(model, X_train)\nshap_values = explainer.shap_values(X_train)\n\nshap.summary_plot(shap_values, X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dd6ac9eda7175a382b6b0adf4e5fe95ecd02e553"},"cell_type":"markdown","source":"\n항목이 예측에 미치는 영향을 보여줍니다. 각 행은 각 feature을 나타냅니다.\t\n\n색상은 실제 항목 값입니다\t\n\n예를 들어 feature 18의 파란색 낮은 값은 모형 예측에 부정적인 영향을 미칩니다 (1이냐 0이냐에서 0이 되겠지요)\t\n\n빨간색 높은 값은 긍정적인 영향을 미칩니다 (1이냐 0이냐에서 1이 되겠지요)\n\nfeature 176은 반대 영향이 있습니다 \t\n\n낮은 값은 긍정적인 영향을 미치며 높은 값은 부정적인 영향을 미칩니다\t\n\n시각화를 하여, 각 feature의 모델에 대한 기여도를 쉽게 파악할 수 있다는 장점이 있습니다.\n\n하지만, 결국 우리가 사용해야 할 feature을 수동으로 선택해야한다는 단점이 존재합니다. \t\n\n따라서, 아래에서 그 작업을 해주는 라이브러리를 사용하겠습니다.(RFECV)"},{"metadata":{},"cell_type":"markdown","source":"### Recursive feature elimination\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model_with_feature_selection(X_train, y_train, X_test, folds=folds, model=None, feature_selector=None):\n    prediction = np.zeros(shape = (len(X_test), 2))\n    scores_train = []\n    scores_valid = []\n    \n    for fold_n, (train_index, valid_index) in enumerate(folds.split(X_train, y_train)):\n        # 1. set train data & test data (fold)\n        X_train_fold, X_valid_fold = X_train[train_index], X_train[valid_index]\n        y_train_fold, y_valid_fold = y_train[train_index], y_train[valid_index]\n        # so that we don't transform the original test data\n        X_test_copy = X_test.copy()\n        \n        # 2. fit feature selector and transform folded data for feature selecting\n        feature_selector.fit(X_train_fold, y_train_fold)\n        X_train_fold = feature_selector.transform(X_train_fold)\n        X_valid_fold = feature_selector.transform(X_valid_fold)\n        X_test_copy = feature_selector.transform(X_test_copy)\n        \n        # 3. train model \n        model.fit(X_train_fold, y_train_fold)\n        \n        # 4. predict train and validation data\n        y_pred_train = model.predict(X_train_fold).reshape(-1,)        \n        y_pred_valid = model.predict(X_valid_fold).reshape(-1,)\n        \n        # 5. calculate roc-auc score \n        train_score = roc_auc_score(y_train_fold, y_pred_train)\n        valid_score = roc_auc_score(y_valid_fold, y_pred_valid)                 \n        scores_train.append(train_score)\n        scores_valid.append(valid_score)\n\n        # 6. predict test data by using predict_proba function\n#         y_pred = model.predict_proba(X_test_copy)[:, 1]\n        y_pred = model.predict_proba(X_test_copy)\n        prediction += y_pred\n\n    prediction /= folds.get_n_splits()\n    prediction = np.argmax(prediction, axis = 1)\n    \n    print(f'Mean train auc: {np.mean(scores_train):.4f}, std: {np.std(scores_train):.4f}.')\n    print(f'Mean valid auc: {np.mean(scores_valid):.4f}, std: {np.std(scores_valid):.4f}.')\n    \n    return scores_valid, prediction\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"우리 버전의 수정된 버전을 작성해 봅니다\t\n\n여기 교차 교차 데이터 내에 RFECV를 추가합니다"},{"metadata":{"trusted":true},"cell_type":"code","source":"# define logistic regression model\nmodel = linear_model.LogisticRegression(class_weight='balanced', penalty='l1', C=0.1, solver='liblinear')\n# define RFECV model\n# 1. min_features_to_select : 선택할 feature 수의 최솟값\n# 2. step : 각 단계마다, 제거할 feature의 갯수(양의 정수) 또는 비율(0~1.0 사이 값)\n# 3. cv : fold model (여기서는 repeated_folds = RepeatedStratifiedKFold(n_splits=20, n_repeats=5, random_state=42) 사용)\nfeature_selector = RFECV(model, min_features_to_select=10, scoring='roc_auc', step=0.1, verbose=0, cv=repeated_folds, n_jobs=-1)\nscores, prediction = train_model_with_feature_selection(X_train.values, y_train, X_test, folds=repeated_folds, model=model, feature_selector=feature_selector)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"오히려, feature selection 이전 모델의 validation score가 조금 더 높은 모습을 확인할 수 있음.\n\nMean valid auc: 0.7124, std: 0.1360. -> Mean valid auc: 0.7071, std: 0.1405."},{"metadata":{},"cell_type":"markdown","source":"## Comparing models\n\n다른 모델을 비교할 수 있습니다 \n\n기본 매개 변수가있는 모델이 제대로 작동하지 않을 수 있으므로 최적화 된 모델을 비교할 가치가 있다고 생각합니다\t\n\n다음과 같이 할 것입니다:\n\n* default parameter로 모델을 학습하고 기본 점수를 확인합니다\t \n* best feature들을 선택합니다\t \n* grid search를 실행합니다 \n* best model을 훈련시키고 다시 점수를 봅니다\t\n\n또한 각 모델에 대한 feature selection을 해봅니다  \n\n그리고 훈련을 더 빠르게 하기 위해 반복하지 않는 간단한 폴드를 사용할 것입니다"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train.drop(['id', 'target'], axis=1)\ny_train = train['target']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. Logistic Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = linear_model.LogisticRegression(class_weight='balanced', penalty='l1', C=0.1, solver='liblinear')\nprint('Default scores')\nscores, prediction = train_model(X_train.values, y_train, X_test, folds=folds, model=model)\nprint()\ntop_features = [i[1:] for i in eli5.formatters.as_dataframe.explain_weights_df(model).feature if 'BIAS' not in i]\nX_train_selected = train[top_features]\ny_train = train['target']\nX_test_selected = test[top_features]\n\nlr = linear_model.LogisticRegression(max_iter=1000)\n\nparameter_grid = {'class_weight' : ['balanced', None],\n                  'penalty' : ['l2', 'l1'],\n                  'C' : [0.001, 0.05, 0.08, 0.01, 0.1, 1.0, 10.0],\n                  'solver': ['liblinear']\n                 }\n\ngrid_search = GridSearchCV(lr, param_grid=parameter_grid, cv=folds, scoring='roc_auc', n_jobs=-1)\ngrid_search.fit(X_train_selected, y_train)\nprint(f'Best score of GridSearchCV: {grid_search.best_score_}')\nprint(f'Best parameters: {grid_search.best_params_}')\n\nprint()\nscores_logreg, prediction = train_model(X_train_selected.values, y_train, X_test_selected, folds=repeated_folds, model=grid_search.best_estimator_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"모델을 최적화하면 실제로 auc 점수가 향상됩니다!\n(valid 기준 auc : 0.6871 -> 0.8515)"},{"metadata":{},"cell_type":"markdown","source":"2. AdaBoost Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = AdaBoostClassifier()\nprint('Default scores')\nscores, prediction = train_model(X_train.values, y_train, X_test, folds=folds, model=model)\nprint()\ntop_features = [i[1:] for i in eli5.formatters.as_dataframe.explain_weights_df(model).feature if 'BIAS' not in i]\nX_train_selected = train[top_features]\ny_train = train['target']\nX_test_selected = test[top_features]\n\n\nabc = AdaBoostClassifier()\n\nparameter_grid = {'n_estimators': [5, 10, 20, 50, 100],\n                  'learning_rate': [0.001, 0.01, 0.1, 1.0, 10.0]\n                 }\n\ngrid_search = GridSearchCV(abc, param_grid=parameter_grid, cv=folds, scoring='roc_auc', n_jobs=-1)\ngrid_search.fit(X_train_selected, y_train)\nprint(f'Best score of GridSearchCV: {grid_search.best_score_}')\nprint(f'Best parameters: {grid_search.best_params_}')\n\nprint()\nscores_abc, prediction = train_model(X_train_selected.values, y_train, X_test_selected, folds=repeated_folds, model=grid_search.best_estimator_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"3. SGD Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = linear_model.SGDClassifier(eta0=1, max_iter=1000, tol=0.0001, loss='modified_huber')\nprint('Default scores')\nscores, prediction = train_model(X_train.values, y_train, X_test, folds=folds, model=model)\nprint()\ntop_features = [i[1:] for i in eli5.formatters.as_dataframe.explain_weights_df(model).feature if 'BIAS' not in i]\nX_train_selected = train[top_features]\ny_train = train['target']\nX_test_selected = test[top_features]\n\nsgd = linear_model.SGDClassifier(eta0=1, max_iter=1000, tol=0.0001)\n\nparameter_grid = {'loss': ['log', 'modified_huber'],\n                  'penalty': ['l1', 'l2', 'elasticnet'],\n                  'alpha': [0.001, 0.01, 0.1, 0.5],\n                  'l1_ratio': [0, 0.15, 0.5, 1.0],\n                  'learning_rate': ['optimal', 'invscaling', 'adaptive']\n                 }\n\ngrid_search = GridSearchCV(sgd, param_grid=parameter_grid, cv=folds, scoring='roc_auc', n_jobs=-1)\ngrid_search.fit(X_train_selected, y_train)\nprint(f'Best score of GridSearchCV: {grid_search.best_score_}')\nprint(f'Best parameters: {grid_search.best_params_}')\n\nprint()\nscores_sgd, prediction = train_model(X_train_selected.values, y_train, X_test_selected, folds=repeated_folds, model=grid_search.best_estimator_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"계수나 항목 중요도 등이 없기 때문에 SVC에서는 Permutation Importance를 사용합니다"},{"metadata":{},"cell_type":"markdown","source":"4. Support Vector Machine"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = SVC(probability=True, gamma='scale')\nprint('Default scores')\nscores, prediction = train_model(X_train.values, y_train, X_test, folds=folds, model=model)\nprint()\nperm = PermutationImportance(model, random_state=1).fit(X_train, y_train)\nselected_weights = eli5.formatters.as_dataframe.explain_weights_df(perm).loc[eli5.formatters.as_dataframe.explain_weights_df(perm)['weight'] != 0]\ntop_features = [i[1:] for i in selected_weights.feature if 'BIAS' not in i]\nX_train_selected = train[top_features]\ny_train = train['target']\nX_test_selected = test[top_features]\n\nsvc = SVC(probability=True, gamma='scale')\n\nparameter_grid = {'C': [0.01, 0.1, 1.0, 10.0, 100.0],\n                  'kernel': ['linear', 'poly', 'rbf'],\n                 }\n\ngrid_search = GridSearchCV(svc, param_grid=parameter_grid, cv=folds, scoring='roc_auc', n_jobs=-1)\ngrid_search.fit(X_train_selected, y_train)\nprint(f'Best score of GridSearchCV: {grid_search.best_score_}')\nprint(f'Best parameters: {grid_search.best_params_}')\n\nprint()\nscores_svc, prediction = train_model(X_train_selected.values, y_train, X_test_selected, folds=repeated_folds, model=grid_search.best_estimator_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2335b870061080430fc25c9e99111357088824b8"},"cell_type":"code","source":"plt.figure(figsize=(12, 8));\nscores_df = pd.DataFrame({'LogisticRegression': scores_logreg})\nscores_df['AdaBoostClassifier'] = scores_abc\nscores_df['SGDClassifier'] = scores_sgd\nscores_df['SVC'] = scores_svc\n\nsns.boxplot(data=scores_df);\nplt.xticks(rotation=45);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f81c4775a537def6405793464109d7e80f32697"},"cell_type":"markdown","source":"logistic regression가 대부분의 다른 모델보다 우수하다는 것을 알 수 있습니다 \n\n다른 모델은이 작은 데이터 세트에서 과적합하거나 작동하지 않는 것 같습니다 "},{"metadata":{"_uuid":"03af3b65d3f687689051ac93662029c4e2f58600"},"cell_type":"markdown","source":"## Feature engineering\n\n항목 생성에는 여러 접근 방식이 있습니다\t\n\n익명화되고 비슷한 항목들이 있으면 행을 기준으로 항목을 계산할 수 있습니다\n\n예를 들어 행 별 평균값 같은 것을 말합니다"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train['mean'] = X_train.mean(axis=1)\nX_train['kurt'] = X_train.kurt(axis=1)\nX_train['mad'] = X_train.mad(axis=1)\nX_train['median'] = X_train.median(axis=1)\nX_train['max'] = X_train.max(axis=1)\nX_train['min'] = X_train.min(axis=1)\nX_train['skew'] = X_train.skew(axis=1)\nX_train['sem'] = X_train.sem(axis=1)\n\nX_test['mean'] = X_test.mean(axis=1)\nX_test['kurt'] = X_test.kurt(axis=1)\nX_test['mad'] = X_test.mad(axis=1)\nX_test['median'] = X_test.median(axis=1)\nX_test['max'] = X_test.max(axis=1)\nX_test['min'] = X_test.min(axis=1)\nX_test['skew'] = X_test.skew(axis=1)\nX_test['sem'] = X_test.sem(axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = linear_model.LogisticRegression(class_weight='balanced', penalty='l1', C=0.1, solver='liblinear')\nprint('Default scores')\nscores, prediction = train_model(X_train.values, y_train, X_test, folds=folds, model=model)\nprint()\ntop_features = itemgetter([int(i[1:]) for i in eli5.formatters.as_dataframe.explain_weights_df(model).feature if 'BIAS' not in i])(X_train.columns)\nX_train_selected = X_train[top_features]\ny_train = train['target']\nX_test_selected = X_test[top_features]\n\nlr = linear_model.LogisticRegression(max_iter=1000)\n\nparameter_grid = {'class_weight' : ['balanced', None],\n                  'penalty' : ['l2', 'l1'],\n                  'C' : [0.001, 0.05, 0.08, 0.01, 0.1, 1.0, 10.0],\n                  'solver': ['liblinear']\n                 }\n\ngrid_search = GridSearchCV(lr, param_grid=parameter_grid, cv=folds, scoring='roc_auc', n_jobs=-1)\ngrid_search.fit(X_train_selected, y_train)\nprint(f'Best score of GridSearchCV: {grid_search.best_score_}')\nprint(f'Best parameters: {grid_search.best_params_}')\n\nprint()\nscores_logreg, prediction = train_model(X_train_selected.values, y_train, X_test_selected, folds=repeated_folds, model=grid_search.best_estimator_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"CV 점수가 feature engineering 이전 모델에 비해 0.04 정도 낮아진 것을 확인할 수 있습니다. -> 이번 case의 경우 효과가 없는걸로.."},{"metadata":{},"cell_type":"markdown","source":"## Scaling the data\n\n과적합을 방지하기 위한 마지막 방법은 데이터의 값을 정규화하는 것입니다\n\n일반적으로 다음과 같은 접근 방식이 있습니다\n\n* 각 폴드에서 데이터를 트레인과 검증용으로 나눈 다음 \n* 트레인데이터 및 검증데이터에 스케일러를 적용한 후 \n* 다시 검증 및 테스트에 적용하는 것입니다\t\n* 앞처럼 다시 진행해 봅니다\t\n\n그러나 Kaggle에서는 테스트 데이터를 즉시 적용할 수 있는 독특한 상황입니다\t\n\n따라서 사용 가능한 모든 데이터에 스케일러를 적용해보기도 합니다\t\n\n데이터를 다시 준비하고 stanard scaler를 사용합니다"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train.drop(['id', 'target'], axis=1)\ny_train = train['target']\nX_test = test.drop(['id'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sc = StandardScaler()\ndata = StandardScaler().fit_transform(np.concatenate((X_train, X_test), axis=0))\nX_train.iloc[:, :] = data[:250]\nX_test.iloc[:, :] = data[250:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = linear_model.LogisticRegression(class_weight='balanced', penalty='l1', C=0.1, solver='liblinear')\nprint('Default scores')\nscores, prediction = train_model(X_train.values, y_train, X_test, folds=folds, model=model)\nprint()\ntop_features = itemgetter([int(i[1:]) for i in eli5.formatters.as_dataframe.explain_weights_df(model).feature if 'BIAS' not in i])(X_train.columns)\nX_train_selected = X_train[top_features]\ny_train = train['target']\nX_test_selected = X_test[top_features]\n\nlr = linear_model.LogisticRegression(max_iter=1000)\n\nparameter_grid = {'class_weight' : ['balanced', None],\n                  'penalty' : ['l2', 'l1'],\n                  'C' : [0.001, 0.05, 0.08, 0.01, 0.1, 1.0, 10.0],\n                  'solver': ['liblinear']\n                 }\n\ngrid_search = GridSearchCV(lr, param_grid=parameter_grid, cv=folds, scoring='roc_auc', n_jobs=-1)\ngrid_search.fit(X_train_selected, y_train)\nprint(f'Best score of GridSearchCV: {grid_search.best_score_}')\nprint(f'Best parameters: {grid_search.best_params_}')\n\nprint()\nscores_logreg, prediction = train_model(X_train_selected.values, y_train, X_test_selected, folds=repeated_folds, model=grid_search.best_estimator_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"StandardScaler()를 통해 데이터를 정규화한 결과, validation auc 값이 소폭 상승한 것을 확인할 수 있습니다.\n0.8515 -> 0.8538"},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# version commit 없이 결과 csv 파일을 download\nimport base64\nimport pandas as pd\nfrom IPython.display import HTML\n\ndef create_download_link( df, title = \"Download CSV file\", filename = \"submission.csv\"):\n    csv = df.to_csv()\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)\n\nsubmission = pd.read_csv(f'{path}/sample_submission.csv')\nsubmission['target'] = prediction\ncreate_download_link(submission)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# submission = pd.read_csv(f'{path}/sample_submission.csv')\n# submission['target'] = prediction\n# submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"점수가 조금 증가했습니다!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}